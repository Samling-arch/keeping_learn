好的，这是根据您的要求，将视频内容整理成的 Obsidian 笔记格式。

### 核心内容汇总

| 场景/问题             | 核心工具/方案                                       |
| :---------------- | :-------------------------------------------- |
| 拓展免费API额度         | `Gemini-balance` 轮询代理                         |
| 在个人服务器上中转API      | Docker 部署 `Gemini-balance`                    |
| 免费容器平台部署API代理     | `cloud cloud` (Cyclic.sh) 部署 `Gemini-balance` |
| AI 辅助编程           | VS Code + `client` (Continue) 插件 + Gemini API |
| 实时音视频对话及汉化        | 自研项目 + AI 编程修改代码                              |
| 国内访问音视频对话应用       | Cloudflare Workers 部署 + 自定义域名                 |
| 长文本理解与文件处理        | Gemini Pro 百万 Token 上下文 (免费版有限制)              |
| 多模态能力（公式识别）       | Gemini Pro 的 OCR 功能                           |
| 模型内置联网搜索          | Gemini 模型内置的谷歌搜索功能                            |
| API 格式转换与国内中转     | `openai-gemini` + Netlify 边缘函数部署              |
| 手机端使用 Gemini      | `LobeChat` 网页客户端部署                            |
| 网页沉浸式翻译           | `Immersive Translate` 插件 + Gemini API         |
| AI 工作流自动化         | `n8n` + Gemini 节点                             |
| 免费使用 `cloud code` | `gemini-for-codeium` 代理项目                     |
| 命令行 AI 编程         | `Gemini CLI`                                  |
| AI 深度研究报告         | `deep-research` 开源项目                          |

> [!TIP] 来源
> - **视频**：[十几个场景榨干AI善人，Gemini 2.5 Pro API又免费了](https://www.bilibili.com/video/BV1Bi3XzZESn/)
> - **UP主**：技术爬爬虾
> - **发布时间**：2025-07-05 17:17:17

---

## 一、Gemini 免费 API 与轮询代理 (Gemini-balance)

这边 `Gemini 1.5 Pro` 的 API 又可以免费用了, 这是所有顶级 AI 大模型里面唯一免费的 API, 免费用户每分钟可以请求$5$次, 每天$100$次, 我们可以使用多个 API Key 组成一个号池, 然后轮询使用, 把免费的次数拓展到无限次, 还能把 API 免费中转到国内无限爽用。

本期视频从 AI 编程, 音视频搜索翻译文件处理, 手机端深度研究, AI 工作流等十几个场景的使用, 来榨干 `Gemini` 免费 API 的全部功能。

在 GITHUB 上面搜索 `Gemini proxy`, 也就是 GEMINI 代理, 我们主要看前两个 Star 数量最高的项目, 这里我们先看第二个项目, `Gemini-balance`, 由 `simon-dance` 大佬开发的 GEMINI 轮询代理服务, 我们可以使用这个项目, 搭建一个 GEMINI API Key 的号池, 然后轮询使用 GEMINI API Key, 这样使得免费额度成倍的增加。

### 1. 海外服务器部署

如果您有海外的云服务器, 推荐使用服务器部署, 没有服务器的话, 也有免费的容器部署方案, 这个我们等下再看, 我们先看服务器部署。

这是我的一台位于美国的云服务器, 注意服务器必须位于海外才能连上 GEMINI 的 API。在服务器上搭建好项目以后, 相当于把 API 中转到了国内。

> [!INFO] 提示
> 爬爬虾之前有一个视频介绍如何获得免费一年的亚马逊云的云服务器, 没有服务器的话, 可以参考这期视频。

**部署步骤：**

1.  **安装 Docker**
    在 LINUX 上面安装 docker, 就执行这个命令：
    ```bash
    curl -fsSL https://get.docker.com -o get-docker.sh
    sudo sh get-docker.sh
    ```
    执行完安装命令以后, 我们再把 docker 启动一下。

2.  **配置项目**
    我们来把这个项目配置一下, 这里我们先新建一个配置文件。
    ```bash
    vi .env
    ```
    在项目里面也有配置文件的样例, 我们打开这个文件, 把前$11$行复制出来粘贴进来。这里唯一需要改的就是最后两行。
    - 倒数第二行填写至少一个 GEMINI 的 API key。
    - 我们需要先注册一个谷歌账户, 然后来到这个地址 `aistudio.google.com/app/apikey` 获取一个 GEMINI 的 API Key。打开这个网站需要国外的上网环境, 如果嫌麻烦, 也可以去某鱼上买成品的 API Key, 几毛钱一个。
    - 点击这个 `get API key` 的按钮, 点击创建 API 密钥, 这里随便选个项目, 如果没有的话, 它会自动生成一个, 然后点击创建密钥。
    - 我们把 API Key 复制下来, 来到配置文件, 把 API key 粘贴上。
    - 然后我们可以换一个谷歌账户, 再创建一个 API 密钥, 填写到配置文件里面, 这样有了两个密钥, 我们的使用次数就翻倍了。
    - 接下来把这里的 `token` 改一下, 我改成 `tech-shrimp`, 也就是技术爬爬虾。
    - 这就配置完成了, 我们按 `ESC` 输入 `:wq!` 回车。

3.  **创建 Docker Compose 文件**
    接下来我们创建一个 `docker-compose` 文件, 注意这里的文件名是 `docker-compose.yml`。
    ```bash
    vi docker-compose.yml
    ```
> [!INFO] 提示
    > 如果不熟悉 `docker-compose` 的话, 可以看一下上期视频, 一个$40$分钟的 docker 实战教程, 里面详细解释了 `docker-compose`。

    然后我们再回到 GITHUB 这边, 在首页有一个 `docker-compose` 文件, 我们把文件里的所有内容都复制下来, 然后粘贴进服务器保存一下。

4.  **启动项目**
    ```bash
    docker-compose up -d
    ```
    如果服务器不是 `root` 用户的话, 需要在前面加 `sudo` 回车。

5.  **验证和使用**
    容器创建好以后, 我们来到浏览器, 输入服务器的公网 IP 地址, 后面端口 `$8000$`。验证令牌填写我们配置文件里配的那个。在首页展示出了我们配置的两个 API 密钥。

    接下来我们找一个 AI 客户端来试一下, 这里还是用我们的老朋友 `LobeChat` (视频中口误为`cherry studio`)。下载安装都是傻瓜式的, 非常简单。
    - 打开软件以后, 在左下角找到设置->模型服务。
    - 我们先看使用谷歌的原始接口, 找到 GEMINI, 这里填写 GEMINI 的 API 密钥, 使用这个原始地址, 我们电脑需要有海外的上网环境。
    - 当然我们也可以使用刚才部署的 `Gemini-balance`。点击下面的添加, 这里的提供商类型, 注意选择 GEMINI, 起个名字, 这里我叫 `Gemini-balance` 确定。
    - 然后我们填写 API 密钥, API 密钥还是填配置文件里这个自定义的 `token`。
    - API 地址, 填服务器的 IP 地址加端口 `$8000$`。
    - 然后点击添加模型, 我们先填一个 `gemini-1.5-pro-latest`, 再填一个 `gemini-1.5-flash-latest`。`Pro` 是一个思考模型, 它的输出速度比较慢, 但是数学跟编程方面很强。
    - 我们在上面找到助手, 在模型这里找到 `Gemini-balance` 的, 我们先试一下 `1.5 Pro`。
    - 我一共对话了两次, 我们回到 `Gemini-balance`, 看一下监控面板, 在 API 调用统计这里显示出了两次调用, 我们看到这两次调用使用的 API Key 是不同的, 这样就分散了请求压力到两个 API Key 上面, 使得免费的请求次数翻倍。如果次数还是不够用, 我们可以在首页再添加更多的 API Key, 达成一个无限量使用的效果。

### 2. 免费容器平台部署 (Cyclic.sh)

`Cyclic.sh` (视频中口误为`cloud cloud`) 是我之前介绍过的一个免费部署 docker 容器的平台。
- 选择 GITHUB 登录, 如果 GITHUB 账号注册超过半年了, 每个月都会获得免费的使用额度, 在上面部署一个 `Gemini-balance` 是足够了。
- 左上角的区域推荐选择新加坡。
- 点击 `Deploy` -> `From Template` -> `Advanced`。
- 项目这里也有一个官方的部署教程。
- 我们先把项目名字填过来, 镜像填写这一串, 规格这里可以把 CPU 调到$1$, 内存调到$512$。
- 下面的 Network, 填写端口 `$8000$`, 然后允许公网访问。
- 接下来在环境变量这里点击 `Add`, 然后我们把教程里这一串添加过来。
- 同样的还是要填写 `PROXY_KEY` 跟 `GEMINI_API_KEYS`。API Key 填写 GEMINI 的 Key, 至少填写一个, 如果想填多个, 后面加逗号再填一个就行了。`PROXY_KEY` 可以不填。
- 保存在下面的 `Volumes` 这里, 点击添加挂载, 路径是 `/app/data` 确认。
- 然后右上角点击部署, 等待了大约$20$多分钟, 这个链接显示 `RUNNING` 就可以使用了。
- 点击以后我们就拥有了公网上的 `Gemini-balance`。我把它接入 `LobeChat` (视频中口误为`cherry studio`)来试一下, API 地址填写他给我分配的这个域名, API 密钥我们填写环境变量里配置的这个, 还是把 `1.5 flash` 跟 `1.5 pro` 两个模型添加过来, 看到功能是正常的, 而且回复速度很快。

## 二、AI 辅助编程 (VS Code)

`Gemini 1.5 Pro` 作为一个思考模型, 它的编程能力其实也非常的强。在大模型竞技场这个网站编程子榜这里, `Gemini 1.5 Pro` 一直都是霸榜的, 看到他比 `Claude 3 Opus` 的分数还高。

这里我们找一套完全开源免费的方案, 把 GEMINI 的 API 接入 AI 编程。

- 我用的编程工具是 VS Code, 先来到这个地址, 把 VS Code 下载并且安装一下。
- 然后我们打开 VS Code, 找到左侧的 Extensions, 安装 `Continue` (视频中口误为`client`) 这款 AI 编程插件。
- 安装完成以后, 我们找到下面的 `Continue`, 右上角的设置。在 `API Provider` 这里, 我们还是选到 `GEMINI`。
- 我们可以直接把 GEMINI 的 API Key 填写到这里, 使用谷歌的原生接口, 不过你的电脑需要一直开启海外的上网环境, `$1.5 Pro` 每天可以使用$100$次。
- 如果次数不够用, 我们可以使用视频开头搭建好的 `Gemini-balance`, 把这个 `Use custom server` 勾选上, 然后把服务器的 IP 地址加 `$8000$` 端口填写过来, API Key 还是填我们配置文件里自定义的那个, 保存一下。
- 在模型这里选到 `gemini-1.5-pro-latest`。
- 我让 AI 设计一个车辆排队过红绿灯的小网页, 中间过程就略过了, 我们看一下最终效果, 基本满足了我的需求, 中间经历了很多轮对话, 我们的 API 非常的稳定, 没有报过错。对于简单的 AI 编程需求, 使用 `Gemini 1.5 Pro` 的免费 API 就足够了。

## 三、实时音视频对话

这是我之前做过的一个使用谷歌 GEMINI 进行实时音视频对话的项目, 可以在这个地址找到项目的源代码, 里面有非常详细的部署文档。

- 我们只需要把 GEMINI 的 API Key 复制出来, 粘贴到这里, 然后点击 `connect`。
- 点击这个麦克风的小按钮, 就可以实时音视频对话。
- > 你好你好, 你知道技术爬爬虾吗? Now has seen for sand, Has a d i...
- 这个项目目前不支持中文, 它是胡言乱语。

刚才我们讲到了使用 GEMINI 进行 AI 编程, 这里正好借助 AI 编程完善一下这个项目, 给他增加上中文的支持。
- 在 `AI Studio` 这里, `stream` 也就是实时的音视频对话, 右上角有一个文档, 在 `language_code` 这里, 只要传一个对应的语种, `Gemini` 就会使用这个语种进行回复。
- 对应我的代码就是在这里加一行。它这里我让 AI 编程帮我来实现一下。
- 我的需求是做一个选择语言的功能, 语言列表直接硬编码在代码里就行了, 使用的时候传入 `language_code` 作为参数。在谷歌的文档里面列出了支持的语言类型, 我把这些语言全都贴给 AI, 让他帮我做一下。
- > 有以下的语言可以使用... (粘贴语言列表)
- 模型还是 `gemini-1.5-pro-latest`, 任务完成。

我把项目从本地启动起来, 在这个设置里面多了可以选择语言的功能, 这里我选择中文, 我们来试一下。
> 你好你好, 有什么我能帮你吗?
> 你知道技术爬爬虾吗?
> 技术爬爬虾, 是一个在多个平台都很活跃的科技博主, 他分享了很多关于计算机知识, 软件DIY和开源项目的实用内容。

项目提供了一键部署到 `Cloudflare Worker` 的功能。
- 点击这个按钮, 然后就会自动部署到 `Cloudflare Worker` 上面。
- 部署上去以后, 我们找到 Cloudflare `Workers and Pages`, 找到我们刚部署的项目设置, 在域和路由这里添加一个自定义的域名, 我们就可以在国内使用了。
- 这里我添加我的技术爬爬虾的免费域名, 之前有一期视频介绍如何获取这么一个免费域名, 然后点击添加域。
- 等待几分钟以后, 我们使用域名, 在浏览器里就可以访问到我们的项目了。
- 这个页面也做了手机端的配适, 我们用手机端来测试一下。
- > 这是什么?
- > 这似乎是一条音频分离器转接线。
- > 你再仔细看看。
- > 看来我上次看错了, 这是一个USB母头转Type-C公头转接器。

## 四、长文本与文件处理能力

首先 `Gemini` 有百万 token 的上下文, 不过免费用户用不了这么多, 这里免费用户 TPM, 也就是每分钟的 token 数限制到了$25$万。

- 我这里有一个全本的三体一, 我直接把它复制到对话框里面, 为了防止 AI 之前的训练数据里面有这本书, 我先进来改一些东西。
- 我把这里改一下, 第$304$我改成$305$, $318$改$328$, $325$改$333$。这一段差不多在书的正中间部分。
- 我的问题是, 叶文洁通过第几次的发射数据, 判断出雷志成是骗他的?
- 我们看到 AI 几秒钟就搜索到了正确答案。这一次对话消耗了$15$万 token, `Gemini` 的超长上下文, 对长文本的检索能力非常的厉害。

`Gemini` 几乎可以处理一切的文件格式。
- 这是一个 excel 表, 我粘贴进来, 它可以成功的读取到 excel 表里面的数据。
- 我还有一个 PDF 的论文, 我让他总结一下, 总结的非常不错, 输出很快。
- 这是论文里面的一个数学公式, 我把它截个图, 我让 `Gemini` 识别一下这个图, 从这里看到它识别的非常精准, 在最下面找到编辑, 可以看到他编写的 `LaTeX`, 跟上面的公式是一模一样的。这 `Gemini` 也是一个原生的多模态大模型, 他的 OCR 能力非常的强。

`Gemini 1.5 Pro` 是一个思考模型, 在下面的按钮里可以调整它的思维链长度。

## 五、内置谷歌搜索

`Gemini` 还有一个强悍之处, 它自带谷歌搜索。我们在联网搜索这里选到模型内置, 就可以使用它内置的谷歌搜索。我现在都很少打开谷歌去搜东西了, 直接交给 `Gemini` 帮我搜索, 结果是又快又准。

我们来试一下, 我问他一个问题, `Grok 2` 什么时候出？ (视频中口误为`GROCK 4`)
> 25年7月4号 (这是一个示例回答)
这个答案给的非常精准, 上面还有引用内容, 列出了信源在哪里, 我们可以打开网页查看它的原始信源。

## 六、API 格式转换 (openai-gemini)

我们来看下一个开源项目 `openai-gemini`。它可以使用无服务器部署, 把 `Gemini` 的 API 转换成 `OpenAI` 的格式, 同时把 `Gemini` 的 API 中转到了国内。

下面提供了好多种部署方式, 我都试了一下, 最好用的还是这个 `Netlify`。
- 我们点击一下这个按钮 `Deploy to netlify`。
- 点击 `Connect to GitHub`, 随便起个项目名字, 点击 `Save`。
- 部署成功以后, 我们获得一个 API 地址, 我把它复制一下。
- 回到 `LobeChat` (视频中口误为`cherry studio`), 点击添加, 这次的模型供应商我们选择 `OpenAI`, 因为 API 已经被转换成 OpenAI 的格式了。
- API 地址填 `https://` 后面接部署地址, 后面是重点, 我们打一个斜杠写 `edge`, 也就是使用它的边缘函数版。`Netlify` 的普通函数, 可能因为 CPU 时钟限制, 输出一半经常被截断, 但是边缘计算版就要稳定很多。
- 这里的 API Key 我们填写 GEMINI 的 API 密钥, 这里只能填一个, 项目不提供轮询。
- 模型还是填 `gemini-1.5-pro-latest`, 还有 `gemini-1.5-flash-latest`。
- 模型提供商选择 `Gemini-Netlify`。
- `Gemini` 的所有强大功能它都有, 唯一点注意的是, 网络搜索不是从这里开启, 我们需要在模型设置这里新添加一个, 比如想用 `$1.5 flash` 加谷歌搜索, 我们在后面加冒号 `search` 添加模型。
- 然后我们用的时候把模型切换到带搜索功能的这个, 我问他今天几号了, 这里成功搜索到了答案。

因为这个 API 已经转换成了 `OpenAI` 的格式, 所以在 `Continue` (视频中口误为`client`) 这里, 模型提供商我们选择 `OpenAI Compatible`。
- `Base URL` 我们还是填这一串项目的部署地址, 斜杠 `edge`。
- 这个 `API Key` 同样的还是填 GEMINI 的 API Key。
- 模型名字填 `gemini-1.5-pro-latest`, 保存在 `Continue` 里面, 也可以正常使用。

## 七、手机端使用 (LobeChat)

之前有观众朋友们问我, 怎么在手机上使用 `Gemini`？最方便的方式就是部署一个网页版的 AI 客户端, 然后手机直接使用网页就可以了。

- 我们回到服务器执行这个命令, 把这个开源的网页客户端 `LobeChat` 部署一下。
- ```bash
  bash <(curl -sSL https://lobe-chat.vercel.app/install.sh)
  ```
- 然后我们在浏览器输入服务器的 IP 地址, 端口 `$3210$` 就进入了 `LobeChat`。
- 点击左上角的小人头 -> 应用设置 -> 语言模型, 把 OpenAI 还有 Ollama 这不相干的都关掉。
- 我们来到 `Gemini` 这里, 填写一个 GEMINI 的 API Key 就行了。因为我的服务器是位于海外的, 所以这里也不用中转, 直接连 `Gemini` 的原生接口就可以了。
- 点击获取模型列表, 然后把你想要的模型填过来, 比如这里 `$1.5 flash` 还有 `$1.5 pro` 两个模型。
- 在上面把模型切换好, 我们把这个地址分享给小伙伴, 或者放到手机上面都可以使用 `Gemini` 了。

> [!INFO] 提示
> 如果没有自己的服务器, 之前的视频里面, 我介绍过一个免费的 docker 容器部署平台, 可以在这上面免费的部署 `LobeChat`, 还可以配置成自己的免费域名, 同样这个地址在国内是可以直连的。

## 八、网页沉浸式翻译

`Immersive Translate` 是一个我常用的翻译网页的工具。
- 我们安装好这个插件以后, 翻译服务选择 `Gemini`。
- 然后填写 GEMINI 的 API Key, 翻译我们不需要太强的模型, 只要他的 RPM 够高, 就是每分钟的请求次数。
- 最高的是这个每分钟可以请求$30$个, 把这个 `gemini-1.0-pro` (视频中口误为`2.0 flashlight`) 选上。
- 当然我们也可以使用视频开头部署的 `Gemini-balance`, 使用 `balance` 的话, 把下面的自定义 API 地址换成服务器的 IP 地址加端口, 上面的 API Key 填我们自己配置的那个。
- 我们来测试一下, 点击这个小圆球, 看到整篇文章都成功完成了翻译。

## 九、AI 工作流 (n8n)

`n8n` 是一个开源的 AI 工作流平台, 当然它也可以很方便的接入 `Gemini`。
- 我们先把它从服务器上部署一下, 就执行这个命令。
- 把第二个命令复制下来, 这里需要改一些东西, 我把这个临时启动换成后台启动, 加一个环境变量, 允许项目使用 HTTP 协议被访问到。
- ```bash
  docker run -it --rm \
  --name n8n \
  -p 5678:5678 \
  -e N8N_SECURE_COOKIE=false \
  -v n8n_data:/home/node/.n8n \
  docker.n8n.io/n8nio/n8n
  ```
- 然后我们访问服务器的 IP 加端口 `$5678$` 就可以看到部署的 AI 工作流 `n8n`。
- 右上角点击创建, 创建一个对话消息, 接下来创建一个 AI 节点, 选择 `AI Agent`。
- 点击模型的加号, 选择这个 `Google Gemini`。
- 点击 `Create New Credential`, 可以填写 GEMINI 的 API Key。当然也可以使用自己部署的 `Gemini` 服务, 把上面的 `Host` 改一下就行了, 最后点击 `Save`。
- 在下面的模型里, 我选择 `$1.5 flash`。
- 点击屏幕下面的 `Open Chat`, 这里给到输出就对接成功了。

> [!INFO] 提示
> 我之前有一个详细视频介绍 `n8n` 的使用一些复杂的案例, 可以去看那个视频, 这里我就不赘述了。

## 十、其他高级应用场景

### 1. `Codeium` 代理 (`gemini-for-codeium`)

在 GITHUB 上面有一个项目叫 `gemini-for-codeium`。`Codeium` (视频中口误为`cloud code`) 是一个很多人喜爱的 AI 编程工具, 不过 `Codeium` 的费用很高。我们可以使用这个代理, 让 `Codeium` 用上 `Gemini` 的 API。项目下面有很详细的部署步骤, 需要填一个大模型, 大模型填 `$1.5 Pro`, 小模型可以填 `$1.5 Flash`。然后先把这个代理的 Python 工程启动起来, 接下来我们使用 `Codeium` 的时候, 配置一个代理, 让他经过代理转发一下, 这样就可以免费的使用 `Codeium` 来进行编码了。步骤还是很简单的, 这里我就不详细了, 如果有需要可以在评论区留言。

### 2. `Gemini CLI`

另外一个 AI 编程工具 `Gemini CLI`, 在 GITHUB 上面短短几天有了$50000$ Star。我们可以使用自己的 GEMINI API 密钥, 每天可以使用$100$次, 如果次数不够用, 我们当然也可以使用 `Gemini-balance`。`Gemini CLI` 也是一个不错的 AI 编程方案。

### 3. 深度研究 (Deep Research)

`Deep Research` 也就是深度研究, 是一个 AI 的进阶用法。像 `ChatGPT`, `Gemini` 的网页端, 还有 `Perplexity` 的网页端, 都是需要开会员才能使用 `Deep Research` 的全部功能。

我们来看一个 GITHUB 上面的开源项目, 叫做 `deep-research`, 它是使用了 `Gemini` 的 API 来达成了深度研究的功能。我们只需要提供给他 API Key 就可以完成深度研究的报告。
- 这是一个开源项目, 下面有很详细的部署文档。当然不想自己部署的话, 我们也可以使用搭建好的成品, 在右边找到这个链接。
- 我们提供一个研究主题, 比如我问 `Gemini 的免费 API 有哪些很酷的用法`。
- 在右上角打开设置, 我们把 GEMINI 的 API 密钥填写过来。当然也可以使用我们自己搭建的代理服务, 把下面的 URL 路径换一下就行了。
- 思维模型选 `$1.5 Pro`, 任务模型选 `$1.5 Flash`, 保存。
- 然后开始, 第一部分是做超级个体, 后面多模态融合跟现实世界交互, 第三部分, 利用百万 token 的上下文做深度分析与知识挖掘, 第四部分 AI 工作流自动化, 第五部分前沿探索与概念性的应用。
- 短短的几个提示词, 完成了一篇非常详细的研究报告, 研究了$321$个网站, 达成了一个很不错的效果。
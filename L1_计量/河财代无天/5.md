
# 1 【计量经济学】多重共线性 (期末过关攻略)

> [!info] 视频来源
> **原视频链接：**[【计量经济学】代有地期末过关攻略](https://www.bilibili.com/video/BV1QJ411h7YX/)
> **UP主：** 河财代无天
> **发布时间：** 2019-12-31

## 1.1 本讲核心问题汇总

| 主要问题 | 核心内容 | 考试重点 |
| :--- | :--- | :--- |
| **多重共线性的概念** | 解释变量之间存在近似或完全的线性关系。分为完全与不完全多重共线性。 | 理解即可，通常不直接考察概念。 |
| **多重共线性的后果** | 参数估计量方差变大、显著性检验（t检验）失效、置信区间变宽。 | **小题、简答题**。 |
| **多重共线性的检验** | 综合分析法、简单相关系数法、辅助回归法（VIF）、条件指数法。 | **大题考点**。需要掌握判断标准和方法名称。 |
| **多重共线性的补救** | 不处理、剔除变量、补充数据、利用先验信息、变换模型、逐步回归、岭回归。 | **大题考点**。需要掌握各种方法的适用条件和基本思想。 |

---

## 1.2 一、引言：多重共线性问题的由来

在我们学习的经典线性回归模型中，有一系列基本假定，当这些假定被违背时，模型就会出现问题：

-   违背 **随机误差项同方差** 假定 → **异方差性** (第四章第二节)
-   违背 **随机误差项无自相关** 假定 → **自相关性** (第四章第三节)
-   违背 **解释变量满秩性** 假定 → **多重共线性** (本章第一节)

**考试定位**:
-   异方差和自相关性会出**大题**。
-   多重共线性只会出**小题**。

**本章讲述逻辑**:
这三类问题的讲述逻辑都是一致的：
1.  **概念**：这是什么？
2.  **后果**：得了这个“病”会有什么症状？
3.  **检验**：如何诊断自己是否得了这个“病”？
4.  **补救**：确诊后，如何治疗？

> [!tip] 学习重点
> 后果、检验方法和补救措施是重点。其中**检验方法**和**补救措施**是重中之重，会考大题。概念不理解也无所谓，考试不考，但理解概念有助于理解后续内容。

---

## 1.3 二、多重共线性的概念

多重共线性是与 **解释变量满秩性** 相反的概念。当模型不满足满秩性时，就会出现多重共线性。

-   **共线性 (Collinearity)**：`共` 指的是解释变量之间，`线性` 指的是线性关系。
-   **线性关系**：一个变量可以用其他变量的线性组合来表示。即：一个变量 = 参数 × 另一个变量 + 参数 × 再一个变量 + ...
    > 一个变量可以用其他变量，参数乘上变量，再求和的方式去表示。

因此，多重共线性就是指解释变量 `X` 之间存在线性关系，可以表示为：
$$
\lambda_1 X_1 + \lambda_2 X_2 + \dots + \lambda_k X_k = 0
$$
在这个式子中，只要有一个 `λ` 不为零，就说明变量间存在线性关系。你可以把任何一个 `X` 移到等式右边，来表示它与其他 `X` 的线性关系。

### 1.3.1 完全多重共线性 (Perfect Multicollinearity)
当解释变量之间的线性关系**严格成立**时。
$$
\lambda_1 X_1 + \lambda_2 X_2 + \dots + \lambda_k X_k = 0
$$
-   **后果**：参数的估计值 `β̂` **不唯一**，不止一组解。这让模型犯了“选择困难症”，导致我们**不能求出**唯一的参数估计值。

### 1.3.2 不完全多重共线性 (Imperfect Multicollinearity)
当解释变量之间的线性关系**近似成立**时。这是现实中更常见的情况。
$$
\lambda_1 X_1 + \lambda_2 X_2 + \dots + \lambda_k X_k \approx 0
$$
例如，上式等于 `$0.001$`，`$0.002$` 这样非常接近零的数。

---

## 1.4 三、不完全多重共线性的后果

不完全多重共线性主要有三个后果：

### 1.4.1 参数估计值的方差变大
参数估计量 `β̂j` 的方差公式为：
$$
\text{Var}(\hat{\beta}_j) = \frac{\sigma^2}{\sum(x_{ji} - \bar{x}_j)^2(1-R_j^2)}
$$
-   这里的 `$R_j^2$` **不是**模型的拟合优度 `$R^2$`。它指的是将某一个解释变量 `$X_j$` 对**所有其他解释变量**做回归得到的判定系数。它衡量了 `$X_j$` 与其他 `$X` 变量的线性相关程度，即**多重共线性的程度**。
-   **逻辑推导**：
    -   模型的多重共线性程度越高 → `$R_j^2$` 越大 ( `$R_j^2$` 介于 `$0$` 和 `$1$` 之间)。
    -   `$R_j^2$` 越大 → `$(1-R_j^2)$` 越小。
    -   `$(1-R_j^2)$` 越小 → `$\frac{1}{1-R_j^2}$` 越大。
    -   最终导致 `$\text{Var}(\hat{\beta}_j)$` 整体变大。
-   **方差膨胀因子 (Variance Inflation Factor, VIF)**：经济学家把 `$\frac{1}{1-R_j^2}$` 这一项命名为方差膨胀因子，因为它导致了方差的“膨胀”。
    $$
    \text{VIF}_j = \frac{1}{1-R_j^2}
    $$

### 1.4.2 显著性检验（t检验）可能失效
t 检验的统计量公式为：
$$
t_j = \frac{\hat{\beta}_j}{\text{se}(\hat{\beta}_j)}
$$
-   **逻辑推导**：
    -   由后果1可知，多重共线性使方差 `$\text{Var}(\hat{\beta}_j)$` 变大。
    -   标准差 `$\text{se}(\hat{\beta}_j)$` 是方差的平方根，所以标准差也变大。
    -   在分子 `$\hat{\beta}_j$` 不变的情况下，分母 `$\text{se}(\hat{\beta}_j)$` 变大，导致整个 `t` 值变小。
-   **影响**：本来一个变量是显著的（`t` 值大于临界值），但因为多重共线性导致 `t` 值变小，甚至可能小于临界值，从而错误地判定该变量不显著。

### 1.4.3 参数的置信区间变宽，精度下降
置信区间的公式为：
$$
[\hat{\beta}_j - t_{\alpha/2} \cdot \text{se}(\hat{\beta}_j), \quad \hat{\beta}_j + t_{\alpha/2} \cdot \text{se}(\hat{\beta}_j)]
$$
-   **逻辑推导**：
    -   多重共线性导致标准差 `$\text{se}(\hat{\beta}_j)$` 变大。
    -   **下限**：`$\hat{\beta}_j$` 减去一个更大的数，导致下限变小（向左移动）。
    -   **上限**：`$\hat{\beta}_j$` 加上一个更大的数，导致上限变大（向右移动）。
-   **影响**：整个置信区间被“拉宽”了，这意味着我们对参数的估计变得不那么精确了。

---

## 1.5 四、多重共线性的检验方法

### 1.5.1 综合分析法
-   **症状**：模型的**整体显著性很好**（`F`检验显著，`$R^2$`很高），但**部分解释变量的 `t` 检验却不显著**。
-   **类比**：一个学生期末考试总分很高，但他有几门并不难的科目却挂科了。这时我们就会怀疑这个学生有问题（可能作弊了）。同理，模型整体很好但个体很差，我们就怀疑模型存在多重共线性。

### 1.5.2 简单相关系数法
-   **原理**：既然多重共线性是解释变量间的线性关系，我们可以直接计算它们两两之间的**简单相关系数 `r`**。
-   **判断标准**：如果某两个解释变量 `$X_i$` 和 `$X_j$` 之间的相关系数 `r` 的**绝对值**很高（比如趋近于`$1$`），则有理由怀疑存在多重共线性。

### 1.5.3 辅助回归法
-   **原理**：这个方法直接利用了后果1中提到的 `$R_j^2$` 和 VIF。
-   **操作**：将某一个解释变量 `$X_j$` 作为被解释变量，用其他所有解释变量对它进行回归（这个回归被称为**辅助回归**）。
-   **判断标准**：
    -   **判定系数 `$R_j^2$`**：如果辅助回归的 `$R_j^2$` 很大 (经验法则是大于 `$0.8$` 或 `$0.9$`)，则表明存在严重的多重共线性。
    -   **方差膨胀因子 VIF**：因为 `$\text{VIF} = 1 / (1 - R_j^2)$`，我们也可以直接用 VIF 判断。经验法则是，如果 `VIF` 大于 `$5$` 或者 `$10$`，则怀疑存在多重共线性。

### 1.5.4 条件指数法
-   **原理**：只需要记住它的特点和标准。
-   **特点**：条件指数 `CI` (Condition Index) 与多重共线性程度**正相关**，`CI` 越大，共线性越严重。
-   **判断标准**：当 `CI` 大于 `$20$` 时，就怀疑模型存在多重共线性。

---

## 1.6 五、多重共线性的补救措施

### 1.6.1 不处理 (Do Nothing)
在某些情况下，可以不采取任何措施。
-   **情况一：后果不严重时**
    -   如果存在多重共线性的模型，其参数估计仍然通过了经济意义检验和统计显著性检验（`t`检验），说明共线性的影响并不致命，后果不严重，可以不处理。
-   **情况二：研究目的仅为预测时**
    -   多重共线性的后果主要影响单个参数的估计和检验，但**不影响对被解释变量 `Y` 的预测值** (`$\hat{Y}_f$`)。
    -   如果研究目的只是为了预测 `Y`，并且预测期内的多重共线性问题仍然保持（结构稳定），那么这个问题就是无关紧要的。

### 1.6.2 剔除变量法
-   **原理**：多重共线性是指一个 `X` 和其他 `X` 存在关系，但它可能只是和其中某几个变量“关系暧昧”，而不是和所有变量都有问题。
-   **操作**：找出并剔除那些引起严重共线性的变量。
-   **前提**：被剔除的变量必须是**不太重要**的变量。不能为了解决共线性而剔除理论上非常重要的核心变量。

### 1.6.3 补充样本数据
-   **原理**：增加新的样本数据，可能会改变或减弱原有样本中变量间的线性关系。

### 1.6.4 利用先验信息
-   **说明**：这个方法比较晦涩，考试也不会考具体操作。只需要记住它的名字，知道它是多重共线性的一种补救方法即可。

### 1.6.5 变换模型形式
-   **主要方法**：**一阶差分模型 (First-Difference Model)**。
-   **操作**：将原模型 `Yt` 与其滞后一期的模型 `Yt-1` 相减，得到一个差分形式的新模型。
    -   原模型：`$Y_t = \beta_0 + \beta_1 X_{1t} + \beta_2 X_{2t} + u_t$`
    -   滞后一期：`$Y_{t-1} = \beta_0 + \beta_1 X_{1,t-1} + \beta_2 X_{2,t-1} + u_{t-1}$`
    -   差分后：`$(Y_t - Y_{t-1}) = \beta_1 (X_{1t} - X_{1,t-1}) + \beta_2 (X_{2t} - X_{2,t-1}) + (u_t - u_{t-1})$`
-   **说明**：同样，只需要记住这个方法的名称，不理解具体推导也没关系。

### 1.6.6 逐步回归法 (Stepwise Regression)
-   **基本思想**：推倒一切，从头再来。
-   **步骤**：
    1.  **建立基础模型**：让被解释变量 `Y` 分别对每一个解释变量 `X` 单独做回归，挑选出 `t` 值和 `$R^2$` 最好的那个 `X` 作为基础变量，构建一个只含有一个解释变量的基础模型。
    2.  **逐步引入新变量**：在基础模型上，逐个尝试引入其他尚未进入模型的变量。
    3.  **检验新模型**：每引入一个新变量，就得到一个新模型。然后检验这个新模型是否满足两个条件：
        -   **所有变量都显著**：新模型中所有解释变量的 `p` 值（或 `t` 值）都必须是显著的。
        -   **调整后 `$R^2$` 增大**：新模型的**调整后判定系数 (Adjusted `$R^2$`)** 必须比引入该变量之前的模型要大。
    4.  **决策**：
        -   如果两个条件都满足，则**接纳**这个新变量，并以此模型为基础，继续尝试引入下一个变量。
        -   如果任一条件不满足，则**抛弃**这个新引入的变量，并且上一个模型（即未引入这个变量时的模型）就是我们找到的**最好的模型**。
-   **考试定位**：一般只考**小题**或**简答题**，考察对这个概念的理解。

### 1.6.7 岭回归法 (Ridge Regression)
-   **说明**：和利用先验信息法一样，只需要记住它是解决多重共线性问题的一种补救方法即可，无需理解其概念。

# 1 计量经济学期末过关 - Part 2: 可决系数 R²

- **原视频链接**: [【计量经济学】代有地期末过关攻略](https://www.bilibili.com/video/BV1QJ411h7YX/)
- **UP主**: 河财代无天
- **发布时间**: 2019-12-31 21:58:44

## 1.1 核心问题汇总

| 问题/要点 (Key Point) | 核心摘要 (Core Summary) |
| :--- | :--- |
| **为何需要$R^2$?** | 需要一个量化指标来衡量样本回归曲线对样本数据的拟合（接近）程度。 |
| **为何不用“残差和”衡量拟合度？** | 残差有正有负，直接求和会相互抵消，导致结果不精确。 |
| **为何不用“残差平方和(RSS)”衡量？** | RSS的大小受被解释变量$Y$的度量单位影响，单位不同RSS值就不同，无法公允比较。 |
| **$R^2$的基本思想是什么？** | 将Y的总波动(TSS)分解为被模型解释的部分(ESS)和未被解释的残差部分(RSS)。$R^2$衡量的是解释部分占总波动的比例。 |
| **$R^2$的计算公式是什么？** | $R^2 = \frac{ESS}{TSS} = 1 - \frac{RSS}{TSS}$。值越大，拟合度越好。 |
| **$R^2$的性质有哪些？** | 1. **范围**: $0 \le R^2 \le 1$。 <br> 2. **含义**: 被解释变量$Y$的变异中，可以由解释变量$X$解释的比例。 |
| **使用$R^2$的前提条件？** | 模型必须满足三点：**1. 线性模型**；**2. 含有截距项**；**3. 使用普通最小二乘法(OLS)估计**。 |
| **$R^2$在多元回归中的缺陷？** | 在模型中增加**任何**解释变量，都会导致$R^2$增大或不变，无法真实反映模型优劣，可能为了提高$R^2$而滥加变量。 |
| **什么是调整的$R^2$？** |  $R_{adj}^2$ 或 $\bar{R}^2$。在$R^2$的基础上，对增加的解释变量个数施加“惩罚”，是更公允的多元回归拟合度指标。 |
| **$R^2$与调整$R^2$的关系？** | 1. 调整$R^2$ ≤ $R^2$。 <br> 2. 增加显著变量时，调整$R^2$会增大；增加不显著变量时，调整$R^2$会减小。 <br> 3. 调整$R^2$可能为负数。 |
| **如何计算$R^2$和调整$R^2$？** | 考试中通常不使用原始定义，而是利用它们与F统计量的关系相互推算。记住**$R^2$、调整$R^2$、F统计量**三者互推的公式。 |
| **$R^2$与相关系数$r$的关系？** | 1. **仅在一元线性回归中**，$R^2 = r^2$。 <br> 2. **区别**: $R^2$总是非负，而$r$可正可负；$R^2$有方向性（X解释Y），而$r$衡量相关性，无方向。 |

---

## 1.2 详细笔记 (课堂内容复现)

### 1.2.1 一、 为什么需要可决系数 ($R^2$)

可决系数($R^2$)是用来衡量我们的**样本回归曲线**，对于这些**样本数据**拟合程度的量化指标。

#### 1.2.1.1 衡量拟合度的初步思考

- **思路**: 样本回归曲线越接近样本点，说明拟合程度越好。真实值与拟合值的差叫**残差**($e_i$)。那么，是不是残差越小，拟合就越好？
- **错误尝试1：残差之和 $\sum e_i$**
    - **问题**: 残差 `真实值 - 拟合值` 是有正有负的。
    
    > 你看，这个点（指向上方的点）的残差是正的，这个点（指向下方的点）的残差是负的。正负正负加起来，很可能**相互抵消**。就算不完全抵消，也损失了信息，用它来衡量拟合程度是不精确的。
- **错误尝试2：残差平方和 $RSS = \sum e_i^2$**
    - 这是我们之前用来推导OLS估计量的目标函数。用它来衡量拟合度行不行？**也不行**。
    - **问题**: 残差平方和的大小，受变量**度量单位**的影响。
    
    > 举个例子，我们研究GDP，单位可以是“万元”，也可以是“百万元”。比如一个数据是“$100$万元”，如果单位改成“万元”，数值就是$100$；如果单位改成“百万元”，数值就是$1$。你这个$Y$的值一旦变化，它的平方就会变，求和之后，整个残差平方和（RSS）都会变。同一个样本数据，仅仅因为单位不一样，算出来的RSS就不一样，那么它还能作为一个**公允的**评价拟合程度的指标吗？不能。

### 1.2.2 二、可决系数 ($R^2$) 的推导逻辑与公式

经过计量经济学家的反复推敲，他们决定用这样一个指标去表示拟合程度。

#### 1.2.2.1 离差平方和的分解

我们把一个观测值 $y_i$ 到其均值 $\bar{y}$ 的距离 ($y_i - \bar{y}$) 看作**总的波动**（或称总变异）。

- **总离差平方和 (Total Sum of Squares, TSS)**: 代表了$Y$的总波动。
$$
TSS = \sum (y_i - \bar{y})^2
$$
- 这个总波动可以被分解为两部分：
    1.  **回归平方和 (Explained Sum of Squares, ESS)**: 从**拟合值** $\hat{y}_i$ 到**均值** $\bar{y}$ 的波动，这是可以被我们的回归模型（由X解释）的部分。
        $$
        ESS = \sum (\hat{y}_i - \bar{y})^2
        $$
    2.  **残差平方和 (Residual Sum of Squares, RSS)**: 从**观测值** $y_i$ 到**拟合值** $\hat{y}_i$ 的波动，这是无法被模型解释的残差部分。
        $$
        RSS = \sum (y_i - \hat{y}_i)^2 = \sum e_i^2
        $$
- **核心关系**:
$$
TSS = ESS + RSS
$$
> 也就是说，**总波动 = 被解释的波动 + 未解释的波动**。

#### 1.2.2.2 $R^2$ 的公式

- **逻辑**: 拟合得越好，意味着残差部分(RSS)越小。如果用 $\frac{RSS}{TSS}$ 来衡量，就是值越小，拟合度越好。这和我们的思维习惯（越大越好）相反。
- **改进**: 计量经济学家们对公式进行了改动，用被解释的部分占总体的比例来表示。
$$
R^2 = \frac{ESS}{TSS}
$$
- 同时，根据 $TSS = ESS + RSS$，我们也可以得到最常用的公式：
$$
R^2 = 1 - \frac{RSS}{TSS}
$$
- **优点**:
    - $R^2$ 的值越大，说明 $RSS$ 越小，$ESS$ 越大，拟合程度越好。这符合我们“**成正比**”的直觉。
    - 这是一个**无量纲**的比例值，不受单位影响。

### 1.2.3 三、关于 $R^2$ 的几点说明

#### 1.2.3.1 $R^2$ 的计算
- 考试中，通常不会让你用原始公式 $1 - \frac{RSS}{TSS}$ 计算，因为一般不会直接给出 $TSS$ 或 $ESS$。
- **核心考法**: 利用 **$R^2$**、**调整的$R^2$** 和 **F统计量** 这三者之间的关系**相互推算**。
- **重要公式**:
    - $R^2$与调整$R^2$的关系:
    $$
    \bar{R}^2 = 1 - (1-R^2)\frac{n-1}{n-k-1}
    $$
    - $R^2$与F统计量的关系:
    $$
    F = \frac{R^2 / k}{(1-R^2) / (n-k-1)}
    $$
    > (注：在某些教材或软件中，F统计量的分子自由度可能是 $k$ 或 $k-1$，分母是 $n-k-1$ 或 $n-k$。视频中提到k为解释变量个数，此处的公式是常见形式。请以你的教材为准，但核心思想是三者可以互推。)
    
    > **看题**: 视频中举例的Eviews结果，`R-squared`就是$R^2$，`Adjusted R-squared`是调整$R^2$，`F-statistic`是F统计量。题目会隐藏其中一个或两个值，让你用给出的值去推算。这三个可以互推，务必背下公式。

#### 1.2.3.2 $R^2$ 的大小
- 从公式 $R^2 = \frac{ESS}{TSS}$ 可以看出，$ESS$ 和 $TSS$ 都是平方和，都是非负的，且 $ESS \le TSS$。
- 所以，$R^2$ 的取值范围是 **$0 \le R^2 \le 1$**。
- $R^2$ **越大**，表明拟合度**越好**。

#### 1.2.3.3 $R^2$ 的文字含义
- $R^2$ 表示的是：**被解释变量 $Y$ 的总变异中，能够由解释变量 $X$ 的变异所解释的比例**。

#### 1.2.3.4 $R^2$ 有效性的前提条件
- 你估计出的 $R^2$ 要想成为一个有效的、可信的拟合度衡量指标，你的回归模型必须满足**三个要求**（可能会考选择题）：
    1.  模型必须是**线性模型** (Y是线性的，不能是 $lnY$ 等形式)。
    2.  模型必须**含有截距项** (即包含 $\beta_0$)。
    3.  估计方法必须是**普通最小二乘法 (OLS)**。
    
    > **看题**: 视频中第二套卷子的选择题第四题。
    > `利用普通最小二乘法，估计下列模型，哪一个模型的R方能够被解释为“Y的总变异中能够由解释变量X变异解释的比例”？`
    > - **A. $lnY = \beta_0 + \beta_1 X_1 + u_i$**: 被解释变量是$lnY$，非线性，Pass。
    > - **B. $Y = \beta_0 + \beta_1 lnX_1 + u_i$**: 解释变量是$lnX_1$，模型对参数仍是线性的，但UP主这里似乎口误认为它非线性，我们以更严谨的定义看，这个模型本身是线性的。但我们先看其他选项。
    > - **D. $Y = \beta_1 X_1 + u_i$**: 这个模型**没有截距项** $\beta_0$，不满足条件，Pass。
    > - **C. $Y = \beta_0 + \beta_1 X_1 + u_i$**: 满足所有条件：线性、有截距项、OLS估计。**所以选C**。

### 1.2.4 四、多元回归中的 $R^2$ 与调整的 $R^2$

$R^2$ 不仅可以衡量一元回归，也可以衡量多元回归。但在多元回归中，它有一个**严重的问题**。

#### 1.2.4.1 $R^2$ 的缺陷
- **问题**: 当你在模型中**增加新的解释变量 $X$** 时，$R^2$ **只会增大，或保持不变**，绝不会减小。
- **后果**: 这会导致一些“别有用心的人”，为了得到一个漂亮的、很高的$R^2$，往模型里**随意添加不重要、不相关的解释变量**。这样一来，$R^2$ 就不再是一个公允的衡量拟合程度的指标了。

#### 1.2.4.2 调整的 $R^2$ ($\bar{R}^2$ 或 $R_{adj}^2$)
- **目的**: “道高一尺，魔高一丈”，为了解决$R^2$的问题，人们发明了**调整的$R^2$**。
- **原理**: 调整的$R^2$会对模型中解释变量的个数施加一个“**惩罚**”。你增加一个解释变量($X$)，它天生会使$R^2$有增大的趋势，但调整的$R^2$会**人为地**给它一个减小的作用力。
- **效果**:
    - 如果你新加入的$X$是一个**很重要的、显著的变量**，它对拟合度的提升效果会**大于**惩罚效果，最终调整的$R^2$会**增大**。
    - 如果你新加入的$X$是一个**无关紧要的、滥竽充数的变量**，它对拟合度的提升效果会**小于**惩罚效果，最终调整的$R^2$会**减小**。
- **结论**: 在比较包含**不同数量解释变量**的多个模型时，我们应该使用**调整的$R^2$** 作为评判标准，因为它更公允。

#### 1.2.4.3 调整$R^2$的性质
- 一般来说，**调整的$R^2$ 总是小于 $R^2$**。
- 由于惩罚项的存在，调整的$R^2$**可能小于0**。
- **计算**: 同样是通过上面提到的公式，用$R^2$来计算。
    - 公式为 $\bar{R}^2 = 1 - (1-R^2)\frac{n-1}{n-k-1}$
    - **$n$**: 样本数据的个数 (number of observations)。
    - **$k$**: **解释变量**的个数。
    > **看题**: 视频中`根据30个印度农户家庭的...数据`，所以样本量 **$n = 30$**。 `食物支出和总收入X的样本数据`，这里只提到了一个解释变量“总收入X”，所以解释变量个数 **$k=1$**。有了$R^2$的值，代入$n$和$k$就能求出调整的$R^2$。

> **看题**: 视频中第二套卷子的选择题第五题。
> `下列关于调整的可决系数和可决系数的叙述，不正确的是哪一个？`
> - **A. 两者均非负**: **错误**。$R^2$非负，但调整$R^2$可能为负。所以这个叙述不正确。
> - **B. 模型中包含的解释变量个数越多，两者相差越大**: **正确**。$X$越多($k$越大)，惩罚力度越大，两者差距会拉大。
> - **C. 在判断多元线性回归模型的优劣时，使用前者（调整$R^2$）更好**: **正确**。因为调整$R^2$更公允。
> - **D. 当模型中增加一个变量时，后者($R^2$)通常会增大，但前者(调整$R^2$)不一定增大**: **正确**。$R^2$必然不减，但调整$R^2$可能增大也可能减小。

### 1.2.5 五、$R^2$ 与相关系数 $r$ 的关系

- **相关系数($r$)**: 衡量两个变量之间线性相关程度和方向的指标。

#### 1.2.5.1 数值关系
- **仅在一元线性回归模型中**，可决系数$R^2$ 正好等于被解释变量与解释变量之间**简单相关系数 $r$ 的平方**。
$$
R^2 = r^2
$$
> **看题**: 视频中第二套卷子判断题第一题 `在一元线性回归模型中，可决系数R方正好等于被解释变量与解释变量简单相关系数的平方`。这是**正确**的。

#### 1.2.5.2 区别
1.  **符号不同**:
    - $R^2$ 是平方项，取值在 $[0, 1]$，总是**非负**的。
    - $r$ 表示相关关系，可正可负，取值在 $[-1, 1]$。它可以表示**正相关**或**负相关**。
2.  **含义不同 (方向性)**:
    - **$R^2$ 有方向性**: 它衡量的是解释变量 $X$ 对被解释变量 $Y$ 的**解释程度** ($X \rightarrow Y$)。
    - **$r$ 无方向性**: 它只衡量 $X$ 和 $Y$ 之间的**相关程度**，说 $X$ 和 $Y$ 相关，与说 $Y$ 和 $X$ 相关是一回事。
好的，遵照您的要求，我将以一个零基础小白的视角，为您详细解析这个AI工作流。输出将严格遵循Obsidian的Markdown格式，包含特殊格式、表格、详尽的细节和通俗的解释。

---
> [!NOTE] 笔记说明
> - 本笔记旨在为零基础用户提供一份“保姆级”的图文教程，详细拆解视频中的每一步。
> - 所有技术术语都将用最通俗的语言解释。
> - 公式将用 `$$` 包裹，这在本笔记中主要指代码片段或关键参数。
> - 特定数字将用 `$` 包裹，例如 `$2000$`。

### **核心工作流总结**

| 步骤序号 | 核心节点/工具 | 一句话概括其作用 | 关键细节 |
| :--- | :--- | :--- | :--- |
| 0 | **准备工作** | 极致了数据平台 | 我们需要一个“中间商”来帮我们拿到微信官方不公开的文章数据，这个平台就是扮演这个角色。 |
| 1 | **触发与设置** | `Start` / `Set` | 这是工作流的开关，并在这里准备好所有需要用到的“身份证”（BIZ）和“通行证”（API Key）。 |
| 2 | **数据处理** | `Code` | 将多个公众号的“身份证”和名字配对打包，方便后续统一处理。 |
| 3 | **循环处理** | `Looping (for...of)` | 像流水线一样，让每个公众号都排好队，一个一个地走完接下来的所有流程。 |
| 4 | **获取文章列表** | `HTTP Request` | 拿着公众号的“身份证”，去“极致了数据”平台，获取该号所有历史文章的标题和链接列表。 |
| 5 | **拆分列表** | `Split in Batches` | 将获取到的一大包文章列表，拆成一篇一篇文章，为下一步单独处理每篇文章做准备。 |
| 6 | **获取文章内容** | `HTTP Request` | 拿着单篇文章的链接，伪装成普通浏览器去访问，把文章的完整网页内容抓下来。 |
| 7 | **提取正文** | `HTML Extract` | 从抓下来的杂乱网页代码中，像用筛子一样，只筛出我们需要的正文部分。 |
| 8 | **格式化正文** | `Code` | 对提取出的文字进行“精装修”，比如分段、排版，并打包成Notion能看懂的格式。 |
| 9 | **存入Notion** | `Notion` / `HTTP Request` | 先在Notion数据库里创建一个新页面（毛坯房），然后把“精装修”好的文章内容填充进去。 |
| 10 | **扩展应用** | `子工作流 (Sub-Workflow)` | 将整理好的文章作为原材料，送入下一个AI工作流（如AI日报生成），进行二次加工和分发。 |

---

# **实时监控公众号：自动采集+分发文章AI工作流**

## **#1 工作流概述与最终效果**

> **一句话概括：** 这是一个能自动“搬运”指定公众号文章，并整理存放到你的Notion笔记里的自动化流程，还能把这些文章作为素材，喂给其他AI工具进行再创作。

这个工作流的核心目标是解决一个痛点：微信公众号官方不提供直接导出文章的接口（API），导致我们很难批量、稳定地保存和使用公众号内容。

通过搭建这个基于`n8n`的工作流，我们可以实现：
1.  **自动采集：** 设定好你想关注的公众号列表（如：量子位、新智元）。
2.  **自动同步：** 工作流会自动运行，抓取这些公众号最新发布的文章。
3.  **自动整理：** 将抓取到的文章，按照`标题`、`来源`、`URL链接`、`发布时间`等字段，整齐地存入你指定的Notion数据库中。
4.  **内容可用：** 保存下来的文章内容是干净的文本，可以直接阅读、搜索，或作为知识库。
5.  **无限扩展：** 在文章同步完成后，可以自动触发后续动作，比如：
    - 发送`Telegram`或`邮件`通知，告诉你今天的文章已经更新完毕。
    - 连接到“AI日报生成”等其他工作流，对新文章进行总结、摘要，并发布到其他平台。

![Pasted image 20230702160000.png](https://raw.githubusercontent.com/username/repo/main/images/workflow_overview.png)
*(这是一个示例图片路径，请在Obsidian中替换为你的截图)*

## **#2 工作流核心原理解析**

> **一句话概括：** 我们通过一个付费的第三方平台（极致了数据）作为“中间人”来获取文章列表，然后用自动化工具（n8n）模拟浏览器访问这些文章链接，最后将内容整理并存入Notion。

整个流程可以拆解为四步：

1.  **获取“路标” (文章列表):**
    - 我们需要知道目标公众号（比如“机器之心”）最近发了哪些文章，每篇文章的标题和链接是什么。
    - 由于微信不直接提供，我们使用一个名为 **“极致了数据”** 的第三方服务。我们向它发出请求，它会返回给我们目标公众号的文章列表。
2.  **访问“目的地” (抓取内容):**
    - 有了文章链接，我们使用`n8n`中的`HTTP Request`节点，去访问这个链接。
    - 这就像在浏览器地址栏输入网址并回车，`n8n`会帮我们把整个网页的HTML代码下载下来。
3.  **“筛出”黄金 (解析内容):**
    - 下载下来的HTML代码包含了大量我们不需要的东西（比如样式、脚本、广告标签等）。
    - 我们用`n8n`的`HTML Extract`节点，像用一个精准的筛子，只把文章的正文内容从HTML代码中提取出来。
4.  **“存入”仓库 (保存到Notion):**
    - 将提取出来的纯文本内容进行格式化（比如处理换行、分段），然后通过`Notion`的API接口，写入到我们指定的数据库页面中。

## **#3 准备工作：极致了数据平台**

> **一句话概括：** 这是我们获取公众号文章数据的“供应商”，需要注册并充值少量金额才能使用它的API服务。

这个工作流能成功的关键，在于有一个可靠的数据源。视频中推荐的是 **“极致了数据”** 平台。

- **它提供什么？**
    - 它提供了多种微信生态的数据API接口，我们这次主要用的是 **“公众号历史发文列表”** 接口。
    - 这个接口可以获取一个公众号的历史文章或当天发布的文章。
- **如何收费？**
    - 这不是免费服务。它采用API按次调用的方式收费。
    - 例如，获取历史发文列表的接口，调用一次的费用是 `$0.06$` 元。
    - 平台会赠送 `$1$` 元的试用额度，你可以先用这个额度测试。如果长期使用，可以充值少量金额（如 `$5$` 或 `$10$`）。
- **需要做什么？**
    1.  前往“极致了数据”官网并注册登录。
    2.  在后台找到“公众号API”部分。
    3.  在这里，你会找到一个非常重要的东西：**API Key**。这个Key相当于你的个人身份凭证，后续请求接口时必须带上。
    4.  可以先充值少量金额以备使用。

> [!IMPORTANT] 关键资产
> 在这个平台上，我们唯一需要获取并保管好的，就是你的 **API Key**。请勿泄露给他人。

## **#4 工作流搭建步骤详解 (n8n)**

### **## 节点1：触发器 (Start Node)**

> **一句话概括：** 这是整个工作流的“启动按钮”。

- **类型：** `On App Launch` 或 `Manually` (手动触发)
- **来源：** 这是`n8n`自带的起始节点。
- **细节：**
    - 在 **调试阶段**，使用 `Manually` (手动触发) 最方便，点一下按钮，工作流就运行一次。
    - 在 **部署阶段**，你可以把它改成 `Schedule` (定时触发)，比如设置成每天早上`9`点自动运行一次，实现真正的自动化。

### **## 节点2：设置参数 (Set Node)**

> **一句话概括：** 在这里创建一个清单，列出我们要抓取的所有公众号的“身份信息”和我们的“通行证”。

- **类型：** `Set`
- **来源：** `n8n` 核心节点。
- **细节：** 这个节点用于定义整个工作流中会用到的全局变量。我们需要定义三个关键值：`BIZ`, `NAME`, 和 `KEY`。

```json
// 在Set节点中，我们设置为JSON格式
{
  "BIZ": [
    "MzI5MTE0MTE5Mw==", // 量子位
    "MzA3NTI2NTAxMw==", // 新智元
    "MjM5NTY0NTc5MA=="  // 机器之心
  ],
  "NAME": [
    "量子位",
    "新智元",
    "机器之心"
  ],
  "KEY": "YOUR_API_KEY_FROM_JIZHILE" // 在这里粘贴你的API Key
}

```

- **参数详解：**
    - **`$$BIZ$$`**: 这是微信公众号的唯一ID，就像每个人的身份证号码一样，独一无二。
        > [!TIP] 如何获取公众号的 `BIZ` 值？
        > 1. 在电脑浏览器中，随便打开一篇该公众号的文章。
        > 2. 在页面空白处右键，点击 **“检查”** (Inspect)，打开开发者工具面板。
        > 3. 在开发者工具面板中，按 `Ctrl + F` (Mac: `Cmd + F`) 快捷键，调出搜索框。
        > 4. 在搜索框中输入 `$$var biz$$` 并回车。
        > 5. 你会找到一行类似 `var biz = "MzI5MTE0MTE5Mw==";` 的代码，引号里的那串字符就是这个公众号的`BIZ`值。复制它。
    - **`$$NAME$$`**: 就是公众号的中文名。这个主要是为了我们自己方便看，与API请求关系不大，但保持对应关系很重要。
    - **`$$KEY$$`**: 就是你在 **“#3 准备工作”** 中，从“极致了数据”平台获取到的API Key。

> [!WARNING] 注意
> `BIZ` 和 `NAME` 必须一一对应！数组的第一个`BIZ`必须是第一个`NAME`对应的公众号。如果顺序错了，数据就会混乱。要添加更多公众号，只需在数组末尾加上一个英文逗号`,`，然后按格式添加新的`BIZ`和`NAME`即可。

### **## 节点3：代码节点 - 合并数据 (Code Node)**

> **一句话概括：** 用一小段代码，把前面分离的`BIZ`和`NAME`两个列表，合并成一个包含“公众号对象”的列表，方便后续处理。

- **类型：** `Code`
- **来源：** `n8n` 核心节点。
- **细节：**
    - **为什么需要它？** 前面的`Set`节点输出了两个独立的列表（一个BIZ列表，一个NAME列表）。为了在后续的循环中能方便地同时拿到一个公众号的BIZ和NAME，我们最好先把它们配对。
    - **代码怎么来？** 视频作者提到，这段`JavaScript`代码是直接向AI提问生成的。这展示了`Code`节点的强大之处：当你发现标准节点无法满足你的特定数据处理需求时，可以用代码来解决。
    - **输入：** 上一个节点输出的`BIZ`数组和`NAME`数组。
    - **输出：** 一个新的数组，每个元素都是一个对象，形如 `{ biz: 'xxx', name: 'yyy' }`。

> [!NOTE] 关于Code节点和AI编程助手
> `n8n`的`Code`节点是万能节点。视频作者提到了他自建了一个“n8n coding助手”，预设了`n8n`节点的输入输出规范。这样，他只需要用自然语言描述需求（例如：“请帮我把输入的两个数组`BIZ`和`NAME`合并成一个对象数组”），AI就能直接生成可以在`n8n`中运行的代码。这是进阶用法，对于初学者，可以先直接使用视频中提供的代码。

### **## 节点4：限制节点 (Limit Node) (可选)**

> **一句话概括：** 一个“节流阀”，在测试时可以只让一个公众号的数据通过，避免浪费API调用次数。

- **类型：** `Limit`
- **来源：** `n8n` 核心节点。
- **细节：**
    - 如果你设置了`3`个公众号，但只想测试第一个，就可以添加这个节点并设置限制为`$1$`。
    - 调试完成后，记得 **禁用或删除** 这个节点，否则它将永远只处理第一个公众号。

### **## 节点5：循环节点 (Loop Over Items Node)**

> **一句话概括：** 这是一个“循环门”，让上一步处理好的公众号列表排队进入，一次只放行一个，确保每个公众号都完整地走完后续所有流程。

- **类型：** `Loop Over Items`
- **来源：** `n8n` 核心节点。
- **细节：**
    - 它会接收一个数组作为输入（来自节点3的合并后数据）。
    - 对于数组中的每一项（每一个公众号对象），它都会执行一遍循环体内的所有节点。
    - 例如，有`3`个公众号，它就会把从“获取文章列表”到“保存到Notion”的整个流程完整地执行`3`遍。

### **## 节点6：HTTP请求 - 获取文章列表 (HTTP Request Node)**

> **一句话概括：** 拿着当前循环到的公众号的`BIZ`和我们的`API Key`，正式向“极致了数据”平台发出请求，要回这篇文章列表。

- **类型：** `HTTP Request`
- **来源：** `n8n` 核心节点。
- **细节：**
    - 这是第一次与外部API进行真实交互，参数必须正确。
    - **导入cURL：** “极致了数据”的API文档页面通常会提供一个`cURL`示例。你可以直接复制这个`cURL`命令，然后在`n8n`的`HTTP Request`节点中点击`Import cURL`，它会自动帮你填好大部分参数。
    - **关键参数配置：**
        - **Request Method:** `$$POST$$` (表示我们要向服务器提交数据)
        - **URL:** `$$https://api.jizhile.com/api/weixin/history/list$$` (这是“极致了数据”提供的API地址)
        - **Authentication:** `None`
        - **Headers:**
            - `Name`: `Content-Type`
            - `Value`: `application/json` (告诉服务器我们发送的是JSON格式数据)
        - **Body Content Type:** `JSON`
        - **Body Parameters:**
            - **`biz`**: 这个值需要动态获取。点击参数值输入框右边的“表达式”按钮，从循环节点(`Loop Over Items`)的输出中，拖拽`biz`字段过来。表达式看起来像 `{{ $json.biz }}`。
            - **`key`**: 同样使用表达式，从节点2 (`Set`)的输出中，拖拽`key`字段过来。表达式看起来像 `{{ $('Set').item.json.KEY }}`。
            - **其他参数** (如`url`, `name`, `page`): 可以根据API文档填写，但`biz`和`key`是必需的。只用`biz`请求，成本最低。
    - **输出：** 如果成功，这个节点会输出一个包含多篇文章信息的数组，每篇文章信息里有`url`（文章链接）、`title`（标题）、`publish_time`（发布时间）等字段。

### **## 节点7：拆分数据 (Split In Batches Node)**

> **一句话概括：** 上一步拿到的是一个“文章包裹”（包含多篇文章的列表），这一步是把包裹拆开，变成一篇篇独立的文章，方便单独处理。

- **类型：** `Split In Batches`
- **来源：** `n8n` 核心节点。
- **细节：**
    - **Field to Split:** 设置为上一个`HTTP Request`节点返回的那个包含文章列表的字段，通常是 `data`。
    - 它的作用和循环节点类似，但更侧重于将一个项目中的数组拆分成多个独立的项目。

### **## 节点8：HTTP请求 - 获取单篇文章内容 (HTTP Request Node)**

> **一句话概括：** 拿着单篇文章的链接，假装成一个真实的浏览器去访问它，把整个网页的HTML源码抓取下来。

- **类型：** `HTTP Request`
- **来源：** `n8n` 核心节点。
- **细节：**
    - **Request Method:** `$$GET$$` (表示我们只想从服务器获取数据)
    - **URL:** 使用表达式，从上一个节点(`Split In Batches`)的输出中，拖拽`url`字段过来。
    - **关键点：伪装浏览器 (User-Agent)**
        - **为什么？** 很多网站（包括微信）会检测请求来源。如果发现是程序（而不是真人浏览器）在访问，可能会拒绝服务。
        - **怎么办？** 我们需要在请求头(`Headers`)里添加一个`User-Agent`，告诉服务器“我是一个普通的Chrome浏览器”。
        - **如何获取 `User-Agent`？**
            1.  **方法一 (手动获取):** 在你的Chrome浏览器中访问任意网站，打开“开发者工具” -> “网络(Network)”面板，刷新页面，随便点击一个请求，在右侧的“标头(Headers)”里找到`User-Agent`并复制。
            2.  **方法二 (视频中演示):** 使用特定网站（视频简介中提供），粘贴文章URL，它会帮你模拟请求并显示出它使用的`User-Agent`。
        - **如何设置？** 在`HTTP Request`节点的`Headers`部分，添加一个名为 `User-Agent` 的头，值就是你复制的内容。
    - **输出：** 整个文章页面的`HTML`代码，是一大串包含了各种标签的文本。

### **## 节点9：HTML提取节点 (HTML Extract Node)**

> **一句话概括：** 用一个“CSS选择器”作为筛子，从刚刚抓取到的混乱HTML代码中，精准地筛出文章正文部分。

- **类型：** `HTML Extract`
- **来源：** `n8n` 核心节点。
- **细节：**
    - **Source Data:** 保持默认，它会自动使用上一个节点的输出（HTML代码）。
    - **CSS Selector:** 这是最关键的参数。它告诉节点要去HTML的哪个位置提取内容。
        > [!TIP] 如何找到正确的CSS选择器？
        > 1. 在浏览器中打开一篇公众号文章。
        > 2. 右键点击，选择“检查”，打开开发者工具。
        > 3. 点击开发者工具左上角的“元素选择”按钮（一个箭头图标）。
        > 4. 将鼠标移动到文章正文区域，你会看到对应的HTML代码被高亮。
        > 5. 观察高亮的代码，寻找一个具有唯一性的`id`或`class`。视频中发现，微信文章正文通常被一个`id`为 `page-content` 的`<div>`元素包裹。`id`是唯一的，是最佳选择。
        > 6. 复制这个`id`值。
    - **配置选择器：**
        - 在`CSS Selector`输入框中填入 `$$#page-content$$`。
        - **`#`** 号代表 `id`。如果是用 `class`，则用 **`.`** 号开头（例如 `.rich_media_content`）。
    - **Return Value:** 选择 `Text`，我们只需要纯文本内容。
    - **Exclude:** 可以用来排除不想要的内容，比如文章底部的广告。同样用CSS选择器定位广告区域并填入此处。
    - **输出：** 相对干净的，但可能格式还不太好的文章正文纯文本。

### **## 节点10：代码节点 - 格式化内容 (Code Node)**

> **一句话概括：** 对提取出来的正文进行“深度精修”，解决排版、字数限制等问题，并打包成Notion能直接“食用”的格式。

- **类型：** `Code`
- **来源：** `n8n` 核心节点。
- **细节：** 这段代码（同样由AI生成）主要做了三件事：
    1.  **内容分块 (Chunking):** Notion的API对一次性写入的文本块有长度限制（大约`$2000$`个字符）。如果文章太长，直接写入会失败。这段代码会自动检测文章长度，如果超过限制，会将其切割成多个小段落。
    2.  **格式化 (Formatting):** 清理文本中多余的换行符、空格等，使排版更美观。
    3.  **转换为Notion Block格式:** 将每个文本段落包装成`Notion API`能识别的`JSON`对象格式。这就像把普通文字装进一个符合Notion规范的“快递盒”里，Notion收到后才知道怎么摆放。
    - **输出：** 一个名为 `blocks` 的数组，里面包含了多个符合Notion API规范的段落对象。

### **## 节点11, 12, 13, 14：Notion集成**

> **一句话概括：** 这是一个组合拳，先在Notion里建一个空白页面（毛坯房），然后通过API把前面处理好的文章内容一块一块地“砌”进去。

这个过程分为几个子步骤，在n8n中通常通过一个子链路和合并节点实现：

1.  **`Notion` 节点 (Create a Page):**
    - **作用：** 在你的`AI资讯`数据库里创建一个新的页面。
    - **配置：**
        - **Resource:** `Database/Page`
        - **Operation:** `Create`
        - **Database ID:** 选择你的Notion数据库。
        - **Properties:** 将页面的属性（标题、来源、URL、发布时间）与前面节点获取到的数据一一对应。例如，`Title`属性的值就拖拽文章的`title`字段过来。
    - **输出：** 一个新创建的、但内容为空的Notion页面，以及这个页面的`ID`。

2.  **`Merge` 节点:**
    - **作用：** 这是一个“等待”节点。它会等待两条路上的数据都准备好再继续。一条路是创建Notion页面（来自上一步），另一条路是格式化好的文章内容（来自节点10）。
    - **配置：** 设置为等待两个输入都到达。

3.  **`HTTP Request` 节点 (Append block children):**
    - **作用：** 这是最后一步，将格式化好的内容块写入到刚刚创建的Notion页面中。
    - **配置：**
        - **Request Method:** `$$PATCH$$` (表示对现有资源进行局部更新)
        - **URL:** `$$https://api.notion.com/v1/blocks/{BLOCK_ID}/children$$`。这里的`{BLOCK_ID}`需要动态替换成第1步中创建的那个页面的`ID`。使用表达式从`Notion`节点的输出中拖拽`Page ID`过来。
        - **Authentication:** `Notion API`。你需要提前在`n8n`的`Credentials`中配置好你的Notion API secret。
        - **Body Parameters (JSON):**
            - `Name`: `children`
            - `Value`: 使用表达式，从`Code`节点（节点10）的输出中，拖拽那个格式化好的 `blocks` 数组过来。表达式看起来像 `{{ $('Code2').item.json.blocks }}`。

执行完这一步，文章内容就成功写入Notion页面了！流程会回到循环节点，开始处理下一个公众号。

## **#5 工作流的扩展与应用**

> **一句话概括：** 当我们有了自动化的“原料生产线”（采集公众号文章），就可以把它对接给各种“深加工车间”（其他AI工作流）。

当所有公众号的文章都采集完毕后（即循环节点结束后），可以连接到其他节点或工作流，实现更高级的玩法：

- **发送通知：** 连接一个`Gmail`或`Telegram`节点，发送一条消息：“今日公众号文章已全部同步完毕！”
- **连接子工作流 (Sub-Workflow):**
    - 将采集到的文章数据，作为输入，传递给另一个专门的 **“AI日报工作流”**。
    - 这个日报工作流可以：
        1.  调用大语言模型（如GPT）的API，对每篇文章进行**总结摘要**。
        2.  将所有摘要整合成一篇图文并茂的AI资讯日报。
        3.  自动生成日报的**网页版**和**长截图**。
        4.  甚至生成**音频播客**。
        5.  最后，将日报、截图、音频链接自动**分发**到你的Telegram粉丝群、微信群等。

这体现了`n8n`这类自动化工具的精髓：**将多个独立的、模块化的工作流串联起来，构建一个强大的、全自动化的内容生产与分发系统。**

## **#6 总结与资源获取**

这个工作流虽然步骤繁多，但每个节点的功能都非常明确。通过拆解，即使是零基础的小白也能理解其原理并动手搭建。核心在于理解“**获取数据 -> 处理数据 -> 应用数据**”的逻辑链条。

- **免费资源:** 视频作者提到，可以添加他的联系方式，免费获取本“自动获取公众号文章”工作流的配置文件，以及其他一些入门级的`n8n`工作流模板。
- **进阶课程:** 作者也推广了他的付费课程《AI自动化大师课》，其中包含了更复杂的工作流（如AI日报、自动生成短视频等）的详细搭建方法，以及`Code`节点的高级实战技巧。

希望这份超详细的笔记能帮助你成功复现并理解这个强大的AI工作流！